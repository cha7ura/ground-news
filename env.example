# ============================================================================
# Ground News Sri Lanka — Environment Configuration
# ============================================================================
#
# Copy this file to one of:
#   env.local        — local development (all services on your machine)
#   env.staging      — staging environment
#   env.production   — production environment
#
# APP_ENV controls which AI providers are used:
#   "local"       — Ollama/LM Studio for embeddings, LM Studio for LLM
#   "production"  — OpenAI for embeddings, OpenRouter for LLM
#
# Supabase is independently configurable — use local or cloud in ANY environment.

APP_ENV=local

# ============================================================================
# Supabase (PostgreSQL + pgvector + Auth)
# ============================================================================
# Supabase works independently of APP_ENV. Point at local or cloud as needed.
#
# --- Option A: Local Supabase (via `supabase start`) ---
# Runs ~14 containers locally. Requires Supabase CLI + Docker.
# Default keys below are from `supabase start` (safe for local dev only).
#
# NEXT_PUBLIC_SUPABASE_URL=http://127.0.0.1:54321
# NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0
# SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU
#
# --- Option B: Cloud Supabase ---
# Get these from: https://supabase.com/dashboard/project/YOUR_PROJECT/settings/api
#
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_KEY=your-service-key

# ============================================================================
# Meilisearch (Full-text search)
# ============================================================================
# Runs locally via docker-compose in all environments.
MEILISEARCH_URL=http://localhost:7700
MEILISEARCH_MASTER_KEY=your-master-key

# ============================================================================
# AI Providers — Production (APP_ENV=production)
# ============================================================================

# OpenAI — embeddings (production only)
OPENAI_API_KEY=sk-your-openai-key
# OPENAI_EMBEDDING_MODEL=text-embedding-ada-002  # default

# OpenRouter — LLM for bias analysis, summaries, tag extraction (production only)
OPENROUTER_API_KEY=your-openrouter-key
# OPENROUTER_MODEL=openai/gpt-4o-mini  # default

# ============================================================================
# AI Providers — Local (APP_ENV=local)
# ============================================================================

# Local Embedding Provider
# Options: "ollama" (default, runs in Docker) or "lmstudio" (requires desktop app)
# EMBEDDING_PROVIDER=ollama
# EMBEDDING_DIMENSIONS=1024

# Ollama (default local embedding provider — runs via docker-compose)
# OLLAMA_BASE_URL=http://localhost:11434/v1
# Available Qwen3-Embedding models (Ollama tag format):
#   qwen3-embedding:0.6b  (recommended - fast, ~2GB VRAM, max 1024 dims)
#   qwen3-embedding:4b    (balanced - ~8GB VRAM, max 2048 dims)
#   qwen3-embedding:8b    (highest quality - ~16GB VRAM, max 4096 dims)
# OLLAMA_EMBEDDING_MODEL=qwen3-embedding:0.6b

# LM Studio (alternative local provider — requires LM Studio desktop app)
# To use: set EMBEDDING_PROVIDER=lmstudio
# LMSTUDIO_BASE_URL=http://localhost:1234/v1
# Available embedding models (LM Studio model name format):
#   text-embedding-qwen3-embedding-0.6b
#   text-embedding-qwen3-embedding-4b
#   text-embedding-qwen3-embedding-8b
# LMSTUDIO_EMBEDDING_MODEL=text-embedding-qwen3-embedding-0.6b
# LMSTUDIO_LLM_MODEL=local-model
# LMSTUDIO_API_KEY=lm-studio

# ============================================================================
# Firecrawl (Article scraping)
# ============================================================================
# Self-hosted via docker-compose (local/staging):
FIRECRAWL_API_URL=http://localhost:3002
# Cloud API (production):
# FIRECRAWL_API_KEY=fc-your-firecrawl-key

# ============================================================================
# Admin Panel
# ============================================================================
# Secret token for admin access — set a strong random string.
# Users must have this value in their 'admin_secret' cookie to access /admin routes.
ADMIN_SECRET=your-admin-secret-here

# ============================================================================
# Logging (optional)
# ============================================================================
# LOG_LEVEL=info          # debug | info | warn | error
# LOG_FORMAT=text         # text | json
